{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "NUM_GPU = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1, 2'\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "# get file path\n",
    "img_path_temp = Path('your/path').rglob('*.png')\n",
    "img_path_pd = pd.DataFrame(img_path_temp, columns = ['path']).astype('str')\n",
    "img_path_pd[['front', 'channel']] = img_path_pd['path'].str.split(' wv ', expand=True)\n",
    "# remove cells not captured by 5 channels\n",
    "temp = img_path_pd[['front', 'channel']].groupby(['front']).count().reset_index()\n",
    "# print(temp['channel'].value_counts())\n",
    "temp = temp[temp['channel']!=5]\n",
    "img_path_pd = img_path_pd.loc[~img_path_pd['front'].isin(temp['front'])]\n",
    "# img_path_pd['channel'] = img_path_pd['channel'].str[:-6] # remove \").jpeg\"\n",
    "img_path_pd.loc[:, 'channel'] = img_path_pd.loc[:, 'channel'].str[:-5] # remove \").png\"\n",
    "# check whether all channels were captured\n",
    "img_label_pd = img_path_pd.copy()\n",
    "img_label_pd = img_label_pd[img_label_pd['channel']=='TL-Brightfield - dsRed']\n",
    "img_label_pd = img_label_pd.drop_duplicates(subset=['front'])\n",
    "img_label_pd.shape\n",
    "\n",
    "img_path_pd['folder'] = img_path_pd['front'].str.split('/').str[-2]\n",
    "img_path_pd['well'] = img_path_pd['front'].str.split('/').str[-1]\n",
    "img_path_pd[['well', 'field']] = img_path_pd['well'].str.split('(', expand=True)\n",
    "img_path_pd = img_path_pd.loc[~img_path_pd['well'].isin(['B - 3', 'G - 10'])]\n",
    "\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['B - 10', 'C - 5', 'C - 9', 'C - 10', 'D - 5',\n",
    "                                          'E - 2', 'E - 7', 'F - 7', 'G - 7']), 'dose'] = 0.\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['C - 2', 'C - 11', 'D - 6', 'D - 8', 'D - 10',\n",
    "                                          'E - 4', 'E - 8', 'F - 3', 'G - 9']), 'dose'] = 0.1\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['B - 5', 'D - 7', 'D - 9', 'D - 11', 'E - 6',\n",
    "                                          'E - 11', 'F - 6', 'F - 10', 'F - 11']), 'dose'] = 0.3\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['B - 4', 'B - 7', 'C - 4', 'E - 5', 'E - 9',\n",
    "                                          'F - 4', 'F - 8', 'G - 5', 'G - 6']), 'dose'] = 1.\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['B - 6', 'D - 2', 'D - 3', 'D - 4', 'E - 3',\n",
    "                                          'F - 5', 'F - 9', 'G - 3', 'G - 4']), 'dose'] = 3.\n",
    "img_path_pd.loc[img_path_pd['well'].isin(['B - 8', 'B - 9', 'C - 3', 'C - 6', 'C - 7',\n",
    "                                          'C - 8', 'E - 10', 'F - 2', 'G - 8']), 'dose'] = 30.\n",
    "img_path_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_np = np.sort(img_path_pd['channel'].unique())\n",
    "folder_np = np.sort(img_path_pd['folder'].unique())\n",
    "dose_np = np.sort(img_path_pd['dose'].unique())\n",
    "\n",
    "# subset of data\n",
    "dose_class = [0, 0.1, 0.3, 1, 3, 30] # [0., 0.1, 0.3, 1., 3., 30.]\n",
    "path_label_pd = img_path_pd.copy()\n",
    "path_label_pd = path_label_pd[path_label_pd['dose'].isin(dose_class)]\n",
    "le = LabelEncoder()\n",
    "path_label_pd['dose'] = le.fit_transform(path_label_pd['dose'])\n",
    "print('label [0, 1, 2, 3, 4, 5]:', le.classes_)\n",
    "path_label_pd = path_label_pd[['front', 'dose']].drop_duplicates()\n",
    "print('path_label_pd.shape =', path_label_pd.shape)\n",
    "pl_train_pd, pl_val_pd = train_test_split(path_label_pd, test_size=0.1, random_state=1, stratify=path_label_pd['dose']) # path_label_train_pandas\n",
    "print('Training size:', pl_train_pd.shape)\n",
    "print('Validation size:', pl_val_pd.shape)\n",
    "\n",
    "img_test = plt.imread('your/image/path')\n",
    "print(img_test.shape)\n",
    "print(np.amax(img_test)*65535)\n",
    "print(np.amin(img_test)*65535)\n",
    "img_norm = (img_test.astype(np.float)-img_test.min())*255.0/(img_test.max()-img_test.min())\n",
    "print(np.amax(img_norm))\n",
    "print(np.amin(img_norm))\n",
    "plt.imshow(img_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH_SIZE_PER_REPLICA = 16\n",
    "GLOBAL_BATCH_SIZE = NUM_GPU * BATCH_SIZE_PER_REPLICA\n",
    "channel = np.sort(img_path_pd['channel'].unique())\n",
    "list_train_ds = tf.data.Dataset.from_tensor_slices((pl_train_pd['front'].to_numpy(), pl_train_pd['dose'].to_numpy()))\n",
    "list_train_ds = list_train_ds.shuffle(buffer_size=pl_train_pd.shape[0])\n",
    "list_val_ds = tf.data.Dataset.from_tensor_slices((pl_val_pd['front'].to_numpy(), pl_val_pd['dose'].to_numpy()))\n",
    "\n",
    "def stack_img(front, label):\n",
    "    img_list = []\n",
    "    file_path = tf.strings.join([front, ' wv ', ch, ').png']) # for png\n",
    "    img_temp = tf.io.decode_png(tf.io.read_file(file_path), dtype=tf.dtypes.uint16)\n",
    "    img_list = [img_temp, img_temp, img_temp]\n",
    "        \n",
    "        \n",
    "    img_stack = tf.concat(img_list, axis=2)\n",
    "    return img_stack, label\n",
    "train = list_train_ds.map(stack_img, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "val = list_val_ds.map(stack_img, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "for image, label in train.take(1):\n",
    "    plt.figure()\n",
    "    plt.imshow(image[:, :, 2])\n",
    "    plt.title(label.numpy())\n",
    "    print('Pixel max:', image.numpy()[:, :, 2].max())\n",
    "    print('Pixel min:', image.numpy()[:, :, 2].min())\n",
    "    print('Image shape:', image.numpy().shape)\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.shuffle(buffer_size=2000, reshuffle_each_iteration=True) # pl_train_pd.shape[0]\n",
    "    ds = ds.batch(GLOBAL_BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=2)\n",
    "    return ds\n",
    "\n",
    "train_batches = configure_for_performance(train)\n",
    "val_batches = configure_for_performance(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_WIDTH = 1024\n",
    "EPOCH_INITIAL = 30\n",
    "BASE_LEARNING_RATE = 0.002\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(512, 512, 3), # 1024\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    _ = tf.keras.layers.Rescaling(1./32767.5, offset=-1)(inputs)\n",
    "    _ = tf.keras.layers.RandomFlip('horizontal_and_vertical')(_)\n",
    "    _ = tf.keras.layers.RandomRotation(0.2)(_)\n",
    "    _ = tf.keras.layers.Conv2D(3, (3, 3), strides=2, padding='same', activation='tanh')(_) # 1024\n",
    "    # base_model\n",
    "    _ = base_model(_)\n",
    "    _ = tf.keras.layers.MaxPool2D(pool_size=2)(_) # 1024\n",
    "    _ = tf.keras.layers.GlobalAveragePooling2D()(_)\n",
    "    _ = tf.keras.layers.Dropout(0.2)(_)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(len(dose_class))(_)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LEARNING_RATE),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('train_v2.1_{:02d}_01_history_log_initial.csv'.format(NUM_EXP), append=False)\n",
    "\n",
    "class save_per_epoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(save_per_epoch, self).__init__()\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save('train_v2.1_{:02d}_temp_{}.h5'.format(NUM_EXP, epoch))\n",
    "\n",
    "class validate_all_val(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(validate_all_val, self).__init__()\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.loss, self.acc = self.model.evaluate(val_batches, verbose=self.verbose)\n",
    "        print(' - all_val_accuracy: {0:.4f}'.format(self.acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCH_INITIAL,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_batches,\n",
    "                    callbacks=[early_stopping, csv_logger, save_per_epoch()])\n",
    "\n",
    "model.save('my_model_{}.h5'.format(NUM_EXP))\n",
    "print('Model saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
